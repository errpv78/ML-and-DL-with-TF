{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense, Dropout, SimpleRNN, RepeatVector\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
    "import tensorflow as tf\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if GPU available\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_for_add = '0123456789+'\n",
    "num_features = len(chars_for_add)\n",
    "char_to_index = dict((c, i) for i, c in enumerate(chars_for_add))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(chars_for_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('74+84', '158')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_samples_for_add():\n",
    "    first = np.random.randint(0,100)\n",
    "    second = np.random.randint(0,100)\n",
    "    sample = str(first) + '+' + str(second)\n",
    "    label = str(first+second)\n",
    "    return sample, label\n",
    "generate_samples_for_add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 128)               17920     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 7, 128)            32896     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 7, 11)             1419      \n",
      "=================================================================\n",
      "Total params: 52,235\n",
      "Trainable params: 52,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_units = 128\n",
    "max_time_steps = 7\n",
    "\n",
    "\n",
    "    # Simple RNN\n",
    "\"\"\"Fully-connected RNN where output is to be fed back to input.\n",
    "    units: Positive integer, dimensionality of the output space.\n",
    "    activation: Activation function to use. Default: hyperbolic \n",
    "    tangent (tanh). If you pass None, no activation is applied (ie.\n",
    "    \"linear\" activation: a(x) = x).\n",
    "    return_sequences: Boolean. Whether to return the last output in\n",
    "    the output sequence, or the full sequence. Default: False.\"\"\"\n",
    "\n",
    "    # Repeat Vector\n",
    "\"\"\"Repeats the input max_time_steps times\"\"\"\n",
    "\n",
    "    # Time distributed layer\n",
    "\"\"\"This wrapper allows to apply a layer to every temporal slice of\n",
    "    an input.\n",
    "    The input should be at least 3D, and the dimension of index one \n",
    "    will be considered to be the temporal dimension.\"\"\"\n",
    "\n",
    "model = Sequential([\n",
    "    SimpleRNN(hidden_units, input_shape=(None, num_features)),\n",
    "    \n",
    "    RepeatVector(max_time_steps),\n",
    "    \n",
    "    SimpleRNN(hidden_units, return_sequences=True),\n",
    "    \n",
    "    TimeDistributed(Dense(num_features, activation='softmax'))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6+30 36\n",
      "(7, 11) (7, 11)\n"
     ]
    }
   ],
   "source": [
    "def vectorize_sample(sample, label):\n",
    "    x = np.zeros((max_time_steps, num_features))\n",
    "    y = np.zeros((max_time_steps, num_features))\n",
    "    diff_x = max_time_steps - len(sample)\n",
    "    diff_y = max_time_steps - len(label)\n",
    "    for i, c in enumerate(sample):\n",
    "        x[i+diff_x, char_to_index[c]] = 1\n",
    "    for i in range(diff_x):\n",
    "        x[i, char_to_index['0']] = 1\n",
    "    for i, c in enumerate(label):\n",
    "        y[i+diff_y, char_to_index[c]] = 1\n",
    "    for i in range(diff_x):\n",
    "        y[i, char_to_index['0']] = 1\n",
    "    return x,y    \n",
    "        \n",
    "e, l = generate_samples_for_add()\n",
    "print(e, l)\n",
    "x, y = vectorize_sample(e, l)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0006+30'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def devectorize_sample(sample):\n",
    "    res = [index_to_char[np.argmax(vec)] for i, vec in enumerate(sample)]\n",
    "    return ''.join(res)\n",
    "\n",
    "devectorize_sample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000036'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devectorize_sample(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 7, 11) (5000, 7, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0090+65'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "def create_dataset(num_samples=5000):\n",
    "    x = np.zeros((num_samples, max_time_steps, num_features))\n",
    "    y = np.zeros((num_samples, max_time_steps, num_features))\n",
    "    for i in range(num_samples):\n",
    "        e, l = generate_samples_for_add()\n",
    "        e, l = vectorize_sample(e, l)\n",
    "        x[i] = e\n",
    "        y[i] = l\n",
    "    return x, y    \n",
    "\n",
    "x, y = create_dataset()\n",
    "print(x.shape, y.shape)\n",
    "devectorize_sample(x[78])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000155'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devectorize_sample(y[78])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.9468 - accuracy: 0.5925 - val_loss: 0.7093 - val_accuracy: 0.5443\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6809 - accuracy: 0.5456 - val_loss: 0.6709 - val_accuracy: 0.5453\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6622 - accuracy: 0.5556 - val_loss: 0.6645 - val_accuracy: 0.5839\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6600 - accuracy: 0.5972 - val_loss: 0.6636 - val_accuracy: 0.6140\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6565 - accuracy: 0.5761 - val_loss: 0.6610 - val_accuracy: 0.6576\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6551 - accuracy: 0.6430 - val_loss: 0.6597 - val_accuracy: 0.6269\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6525 - accuracy: 0.6254 - val_loss: 0.6580 - val_accuracy: 0.6161\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6506 - accuracy: 0.6062 - val_loss: 0.6573 - val_accuracy: 0.6079\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6473 - accuracy: 0.6057 - val_loss: 0.6575 - val_accuracy: 0.6073\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6449 - accuracy: 0.6185 - val_loss: 0.6545 - val_accuracy: 0.5973\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6406 - accuracy: 0.6188 - val_loss: 0.6532 - val_accuracy: 0.5949\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6367 - accuracy: 0.6214 - val_loss: 0.6518 - val_accuracy: 0.6200\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6325 - accuracy: 0.6217 - val_loss: 0.6502 - val_accuracy: 0.6343\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6250 - accuracy: 0.6363 - val_loss: 0.6420 - val_accuracy: 0.6420\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.6124 - accuracy: 0.6465 - val_loss: 0.6261 - val_accuracy: 0.6423\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5997 - accuracy: 0.6585 - val_loss: 0.6166 - val_accuracy: 0.6313\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5810 - accuracy: 0.6637 - val_loss: 0.5957 - val_accuracy: 0.6587\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.5573 - accuracy: 0.6782 - val_loss: 0.5674 - val_accuracy: 0.6657\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5259 - accuracy: 0.6913 - val_loss: 0.5345 - val_accuracy: 0.6841\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.4911 - accuracy: 0.7094 - val_loss: 0.5001 - val_accuracy: 0.6910\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4510 - accuracy: 0.7190 - val_loss: 0.4591 - val_accuracy: 0.7066\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.4127 - accuracy: 0.7357 - val_loss: 0.4235 - val_accuracy: 0.7257\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.3760 - accuracy: 0.7498 - val_loss: 0.3815 - val_accuracy: 0.7366\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3341 - accuracy: 0.7703 - val_loss: 0.3420 - val_accuracy: 0.7523\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3016 - accuracy: 0.7756 - val_loss: 0.3207 - val_accuracy: 0.7541\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2729 - accuracy: 0.7839 - val_loss: 0.2840 - val_accuracy: 0.7724\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2484 - accuracy: 0.7929 - val_loss: 0.2618 - val_accuracy: 0.7847\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2256 - accuracy: 0.8026 - val_loss: 0.2415 - val_accuracy: 0.7827\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2052 - accuracy: 0.8096 - val_loss: 0.2211 - val_accuracy: 0.7954\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1881 - accuracy: 0.8149 - val_loss: 0.2072 - val_accuracy: 0.8056\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1723 - accuracy: 0.8205 - val_loss: 0.1925 - val_accuracy: 0.8007\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1584 - accuracy: 0.8247 - val_loss: 0.1836 - val_accuracy: 0.8003\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1473 - accuracy: 0.8261 - val_loss: 0.1689 - val_accuracy: 0.8103\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1412 - accuracy: 0.8225 - val_loss: 0.1658 - val_accuracy: 0.8030\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1288 - accuracy: 0.8276 - val_loss: 0.1535 - val_accuracy: 0.8141\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1188 - accuracy: 0.8301 - val_loss: 0.1359 - val_accuracy: 0.8150\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1059 - accuracy: 0.8353 - val_loss: 0.1290 - val_accuracy: 0.8200\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0997 - accuracy: 0.8346 - val_loss: 0.1251 - val_accuracy: 0.8176\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0923 - accuracy: 0.8349 - val_loss: 0.1136 - val_accuracy: 0.8217\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0889 - accuracy: 0.8315 - val_loss: 0.1135 - val_accuracy: 0.8113\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0812 - accuracy: 0.8315 - val_loss: 0.1052 - val_accuracy: 0.8180\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0784 - accuracy: 0.8318 - val_loss: 0.1069 - val_accuracy: 0.8180\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0754 - accuracy: 0.8291 - val_loss: 0.0965 - val_accuracy: 0.8186\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0668 - accuracy: 0.8324 - val_loss: 0.0933 - val_accuracy: 0.8174\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0629 - accuracy: 0.8344 - val_loss: 0.0861 - val_accuracy: 0.8121\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0582 - accuracy: 0.8322 - val_loss: 0.0810 - val_accuracy: 0.8174\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0524 - accuracy: 0.8346 - val_loss: 0.0789 - val_accuracy: 0.8174\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0481 - accuracy: 0.8355 - val_loss: 0.0727 - val_accuracy: 0.8193\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0465 - accuracy: 0.8318 - val_loss: 0.0679 - val_accuracy: 0.8276\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0421 - accuracy: 0.8354 - val_loss: 0.0655 - val_accuracy: 0.8233\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0385 - accuracy: 0.8330 - val_loss: 0.0614 - val_accuracy: 0.8173\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0348 - accuracy: 0.8338 - val_loss: 0.0606 - val_accuracy: 0.8204\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0354 - accuracy: 0.8328 - val_loss: 0.0583 - val_accuracy: 0.8204\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0329 - accuracy: 0.8307 - val_loss: 0.0633 - val_accuracy: 0.8141\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0357 - accuracy: 0.8314 - val_loss: 0.0856 - val_accuracy: 0.8046\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0601 - accuracy: 0.8147 - val_loss: 0.1220 - val_accuracy: 0.7897\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0573 - accuracy: 0.8126 - val_loss: 0.0683 - val_accuracy: 0.8160\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0375 - accuracy: 0.8286 - val_loss: 0.0602 - val_accuracy: 0.8150\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0292 - accuracy: 0.8305 - val_loss: 0.0497 - val_accuracy: 0.8189\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0235 - accuracy: 0.8317 - val_loss: 0.0457 - val_accuracy: 0.8214\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0210 - accuracy: 0.8323 - val_loss: 0.0445 - val_accuracy: 0.8194\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0193 - accuracy: 0.8324 - val_loss: 0.0439 - val_accuracy: 0.8200\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0184 - accuracy: 0.8317 - val_loss: 0.0422 - val_accuracy: 0.8187\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0176 - accuracy: 0.8309 - val_loss: 0.0421 - val_accuracy: 0.8204\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0164 - accuracy: 0.8315 - val_loss: 0.0383 - val_accuracy: 0.8240\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0155 - accuracy: 0.8315 - val_loss: 0.0378 - val_accuracy: 0.8217\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0151 - accuracy: 0.8316 - val_loss: 0.0376 - val_accuracy: 0.8227\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0145 - accuracy: 0.8317 - val_loss: 0.0381 - val_accuracy: 0.8177\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 0.8299 - val_loss: 0.0374 - val_accuracy: 0.8209\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0133 - accuracy: 0.8316 - val_loss: 0.0356 - val_accuracy: 0.8207\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 0.8297 - val_loss: 0.0358 - val_accuracy: 0.8177\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0118 - accuracy: 0.8314 - val_loss: 0.0350 - val_accuracy: 0.8209\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.8303 - val_loss: 0.0331 - val_accuracy: 0.8210\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0107 - accuracy: 0.8304 - val_loss: 0.0362 - val_accuracy: 0.8220\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0106 - accuracy: 0.8308 - val_loss: 0.0336 - val_accuracy: 0.8207\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0099 - accuracy: 0.8305 - val_loss: 0.0326 - val_accuracy: 0.8197\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0091 - accuracy: 0.8305 - val_loss: 0.0327 - val_accuracy: 0.8190\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0088 - accuracy: 0.8301 - val_loss: 0.0300 - val_accuracy: 0.8206\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0083 - accuracy: 0.8305 - val_loss: 0.0308 - val_accuracy: 0.8223\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0079 - accuracy: 0.8306 - val_loss: 0.0301 - val_accuracy: 0.8220\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 0.8296 - val_loss: 0.0302 - val_accuracy: 0.8216\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 0.8304 - val_loss: 0.0301 - val_accuracy: 0.8201\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 0.8296 - val_loss: 0.0289 - val_accuracy: 0.8229\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0068 - accuracy: 0.8304 - val_loss: 0.0288 - val_accuracy: 0.8233\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0067 - accuracy: 0.8292 - val_loss: 0.0286 - val_accuracy: 0.8237\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 0.8299 - val_loss: 0.0287 - val_accuracy: 0.8211\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 0.8299 - val_loss: 0.0285 - val_accuracy: 0.8214\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 0.8299 - val_loss: 0.0262 - val_accuracy: 0.8214\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 0.8306 - val_loss: 0.0274 - val_accuracy: 0.8229\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 0.8295 - val_loss: 0.0284 - val_accuracy: 0.8246\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 0.8299 - val_loss: 0.0277 - val_accuracy: 0.8226\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 0.8299 - val_loss: 0.0306 - val_accuracy: 0.8204\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 0.8296 - val_loss: 0.0269 - val_accuracy: 0.8210\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0048 - accuracy: 0.8295 - val_loss: 0.0261 - val_accuracy: 0.8204\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 0.8293 - val_loss: 0.0262 - val_accuracy: 0.8244\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 0.8296 - val_loss: 0.0265 - val_accuracy: 0.8241\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 0.8294 - val_loss: 0.0256 - val_accuracy: 0.8233\n",
      "Epoch 98/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 0.8301 - val_loss: 0.0251 - val_accuracy: 0.8230\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 0.8292 - val_loss: 0.0253 - val_accuracy: 0.8226\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0039 - accuracy: 0.8292 - val_loss: 0.0248 - val_accuracy: 0.8247\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 0.8297 - val_loss: 0.0260 - val_accuracy: 0.8229\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 0.8298 - val_loss: 0.0236 - val_accuracy: 0.8216\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 0.8286 - val_loss: 0.0255 - val_accuracy: 0.8217\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 0.8299 - val_loss: 0.0240 - val_accuracy: 0.8223\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 0.8300 - val_loss: 0.0245 - val_accuracy: 0.8221\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0033 - accuracy: 0.8286 - val_loss: 0.0241 - val_accuracy: 0.8217\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 0.8290 - val_loss: 0.0239 - val_accuracy: 0.8231\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 0.8295 - val_loss: 0.0243 - val_accuracy: 0.8236\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.8301 - val_loss: 0.0234 - val_accuracy: 0.8241\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.8286 - val_loss: 0.0243 - val_accuracy: 0.8223\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.8299 - val_loss: 0.0233 - val_accuracy: 0.8207\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0028 - accuracy: 0.8290 - val_loss: 0.0231 - val_accuracy: 0.8237\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.8290 - val_loss: 0.0244 - val_accuracy: 0.8219\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 0.8292 - val_loss: 0.0227 - val_accuracy: 0.8234\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 0.8298 - val_loss: 0.0233 - val_accuracy: 0.8217\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.8294 - val_loss: 0.0227 - val_accuracy: 0.8233\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 0.8292 - val_loss: 0.0234 - val_accuracy: 0.8249\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 0.8298 - val_loss: 0.0234 - val_accuracy: 0.8236\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 0.8291 - val_loss: 0.0230 - val_accuracy: 0.8240\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0023 - accuracy: 0.8294 - val_loss: 0.0240 - val_accuracy: 0.8214\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 0.8296 - val_loss: 0.0227 - val_accuracy: 0.8219\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0021 - accuracy: 0.8289 - val_loss: 0.0228 - val_accuracy: 0.8217\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 0.8294 - val_loss: 0.0226 - val_accuracy: 0.8223\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0021 - accuracy: 0.8296 - val_loss: 0.0226 - val_accuracy: 0.8227\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 0.8295 - val_loss: 0.0223 - val_accuracy: 0.8229\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.8295 - val_loss: 0.0223 - val_accuracy: 0.8224\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 0.8294 - val_loss: 0.0221 - val_accuracy: 0.8237\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 0.8290 - val_loss: 0.0224 - val_accuracy: 0.8210\n",
      "Epoch 129/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.8289 - val_loss: 0.0218 - val_accuracy: 0.8239\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.8298 - val_loss: 0.0218 - val_accuracy: 0.8224\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 0.8294 - val_loss: 0.0227 - val_accuracy: 0.8217\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 0.8290 - val_loss: 0.0220 - val_accuracy: 0.8229\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 0.8290 - val_loss: 0.0225 - val_accuracy: 0.8237\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 0.8290 - val_loss: 0.0212 - val_accuracy: 0.8239\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 0.8297 - val_loss: 0.0228 - val_accuracy: 0.8221\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0016 - accuracy: 0.8290 - val_loss: 0.0227 - val_accuracy: 0.8211\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 0.8291 - val_loss: 0.0215 - val_accuracy: 0.8227\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0015 - accuracy: 0.8294 - val_loss: 0.0211 - val_accuracy: 0.8237\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 0.8292 - val_loss: 0.0217 - val_accuracy: 0.8243\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 0.8299 - val_loss: 0.0212 - val_accuracy: 0.8229\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 0.8296 - val_loss: 0.0214 - val_accuracy: 0.8239\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 0.8293 - val_loss: 0.0222 - val_accuracy: 0.8224\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 0.8295 - val_loss: 0.0207 - val_accuracy: 0.8223\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 0.8296 - val_loss: 0.0213 - val_accuracy: 0.8233\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 0.8298 - val_loss: 0.0221 - val_accuracy: 0.8229\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 0.8294 - val_loss: 0.0207 - val_accuracy: 0.8231\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 0.8293 - val_loss: 0.0212 - val_accuracy: 0.8227\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 0.8291 - val_loss: 0.0217 - val_accuracy: 0.8223\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 0.8290 - val_loss: 0.0211 - val_accuracy: 0.8217\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 0.8297 - val_loss: 0.0210 - val_accuracy: 0.8223\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 0.8295 - val_loss: 0.0224 - val_accuracy: 0.8230\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0012 - accuracy: 0.8289 - val_loss: 0.0210 - val_accuracy: 0.8230\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 0.8297 - val_loss: 0.0204 - val_accuracy: 0.8223\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 0.8295 - val_loss: 0.0219 - val_accuracy: 0.8236\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0011 - accuracy: 0.8293 - val_loss: 0.0206 - val_accuracy: 0.8227\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 0.8293 - val_loss: 0.0214 - val_accuracy: 0.8227\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 0.8295 - val_loss: 0.0205 - val_accuracy: 0.8223\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 0.8294 - val_loss: 0.0214 - val_accuracy: 0.8223\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 0.8296 - val_loss: 0.0206 - val_accuracy: 0.8223\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.9665e-04 - accuracy: 0.8296 - val_loss: 0.0208 - val_accuracy: 0.8211\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 9.8077e-04 - accuracy: 0.8293 - val_loss: 0.0215 - val_accuracy: 0.8227\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 9.6366e-04 - accuracy: 0.8295 - val_loss: 0.0206 - val_accuracy: 0.8226\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 9.4628e-04 - accuracy: 0.8295 - val_loss: 0.0209 - val_accuracy: 0.8233\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.3267e-04 - accuracy: 0.8294 - val_loss: 0.0209 - val_accuracy: 0.8234\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 9.1564e-04 - accuracy: 0.8296 - val_loss: 0.0217 - val_accuracy: 0.8224\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 9.1324e-04 - accuracy: 0.8294 - val_loss: 0.0204 - val_accuracy: 0.8224\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 8.8629e-04 - accuracy: 0.8294 - val_loss: 0.0204 - val_accuracy: 0.8234\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.7281e-04 - accuracy: 0.8293 - val_loss: 0.0206 - val_accuracy: 0.8231\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.5338e-04 - accuracy: 0.8294 - val_loss: 0.0209 - val_accuracy: 0.8231\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 8.4398e-04 - accuracy: 0.8298 - val_loss: 0.0209 - val_accuracy: 0.8224\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 17ms/step - loss: 8.2733e-04 - accuracy: 0.8294 - val_loss: 0.0205 - val_accuracy: 0.8226\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.2419e-04 - accuracy: 0.8293 - val_loss: 0.0211 - val_accuracy: 0.8229\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 8.1323e-04 - accuracy: 0.8291 - val_loss: 0.0205 - val_accuracy: 0.8224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faa647ab390>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training\n",
    "# Callbacks: utilities called at certain points during model training.\n",
    "# on_epoch_begin\tcalled at the beginning of every epoch.\n",
    "# on_epoch_end\tcalled at the end of every epoch.\n",
    "l_cb = LambdaCallback(\n",
    "    on_epoch_end = lambda e, l:print('{:.2f}'.format(l['val_accuracy']), end=' _ ')\n",
    ")\n",
    "\n",
    "# EarlyStopping: Stop training when a monitored metric has stopped improving.\n",
    "# monitor\tQuantity to be monitored.\n",
    "# patience\tNumber of epochs with no improvement after which training will be stopped.\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "\n",
    "# verbose\t0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
    "model.fit(x, y, epochs=500, batch_size=256, validation_split=0.2,\n",
    "         verbose=True , callbacks=[es_cb, l_cb])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInput: 0035+20 Out:0000055 Pred: 0000155\u001b[0m\n",
      "\u001b[31mInput: 00025+9 Out:0000034 Pred: 0000134\u001b[0m\n",
      "\u001b[31mInput: 0038+37 Out:0000075 Pred: 0002175\u001b[0m\n",
      "\u001b[31mInput: 0001+37 Out:0000038 Pred: 0000238\u001b[0m\n",
      "\u001b[31mInput: 0013+85 Out:0000098 Pred: 0001198\u001b[0m\n",
      "\u001b[31mInput: 0028+19 Out:0000047 Pred: 0001247\u001b[0m\n",
      "\u001b[31mInput: 0070+47 Out:0000117 Pred: 0002117\u001b[0m\n",
      "\u001b[31mInput: 0004+96 Out:0000100 Pred: 0003100\u001b[0m\n",
      "\u001b[31mInput: 0047+11 Out:0000058 Pred: 0000458\u001b[0m\n",
      "\u001b[31mInput: 0051+79 Out:0000130 Pred: 0001130\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = create_dataset(10)\n",
    "preds = model.predict(x_test)\n",
    "\n",
    "for i, pred in enumerate(preds):\n",
    "    y = devectorize_sample(y_test[i])\n",
    "    y_pred = devectorize_sample(pred)\n",
    "    col = 'green'\n",
    "    if y!=y_pred:\n",
    "        col='red'\n",
    "    out = 'Input: '+devectorize_sample(x_test[i])+ ' Out:'+y+' Pred: '+y_pred\n",
    "    print(colored(out, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
